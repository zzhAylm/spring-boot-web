eureka:
  user:
    name: admin
    password: 123456
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
  client:
    register-with-eureka: true # 不需要将自己注册到注册中心
    serviceUrl:
      defaultZone: "https://${eureka.user.name}:${eureka.user.password}@eureka-test.suixingpay.com/eureka/"

mybatis-plus:
  mapper-locations: classpath:/mapper/*.xml
  type-aliases-package: com.zzh.springboot3
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl  # 使用标准输出日志

spring:
  kafka:
#    bootstrap-servers: localhost:9092 # kafka集群信息，多个用逗号间隔
    bootstrap-servers: 22.50.2.203:9092,22.50.2.206:9092,22.50.2.212:9092 # kafka集群信息，多个用逗号间隔
    # 生产者
    producer:
      # 重试次数，设置大于0的值，则客户端会将发送失败的记录重新发送
      retries: 3
      batch-size: 16384 #批量处理大小，16K
      buffer-memory: 33554432 #缓冲存储大，32M
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者
    consumer:
      # 消费者组
      group-id: TestGroup
      # 是否自动提交
      enable-auto-commit: false
      # 消费偏移配置
      # none：如果没有为消费者找到先前的offset的值,即没有自动维护偏移量,也没有手动维护偏移量,则抛出异常
      # earliest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从头开始消费
      # latest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从最新的数据开始消费
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 监听
    listener:
      # record：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # batch：当每一批poll()的数据被ListenerConsumer处理之后提交
      # time：当每一批poll()的数据被ListenerConsumer处理之后，距离上次提交时间大于TIME时提交
      # count：当每一批poll()的数据被ListenerConsumer处理之后，被处理record数量大于等于COUNT时提交
      # count_time：TIME或COUNT中有一个条件满足时提交
      # manual：当每一批poll()的数据被ListenerConsumer处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # manual_immediate：手动调用Acknowledgment.acknowledge()后立即提交，一般推荐使用这种
      ack-mode: MANUAL_IMMEDIATE
  data:
    redis:
      host: 127.0.0.1
      port: 6379
  shardingsphere:
    datasource:
      names: write_db0,write_db1,read1_db0,read1_db1,read2_db0,read2_db1
      write_db0:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds0?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
      write_db1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds1?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
      read1_db0:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds0?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
      read1_db1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds1?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
      read2_db0:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds0?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
      read2_db1:
        type: com.zaxxer.hikari.HikariDataSource
        jdbc-url: jdbc:mysql://127.0.0.1:3306/ds1?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull
        username: root
        password: 123456
        driver-class-name: com.mysql.cj.jdbc.Driver
    rules:
      sharding:
        # 配置分片规则
        tables:
          # 配置 t_order 表规则
          t_order:
            actualDataNodes: read_write_db${0..1}.t_order_${0..1}
            # 配置分库策略
            databaseStrategy:
              standard:
                shardingColumn: id
                shardingAlgorithmName: order_database_inline
            # 配置分表策略
            tableStrategy:
              standard:
                shardingColumn: id
                shardingAlgorithmName: order_table_inline
            keyGenerateStrategy:
              column: id
              key-generator-name: snowflake
          t_user:
            actualDataNodes: read_write_db${0..1}.t_user_${0..1}
            # 配置分库策略
            databaseStrategy:
              complex:
                sharding-columns: id,role_id
                shardingAlgorithmName: user_database_complex
            # 配置分表策略
            tableStrategy:
              complex:
                sharding-columns: id,role_id
                shardingAlgorithmName: user_table_complex
            keyGenerateStrategy:
              column: id
              key-generator-name: snowflake
          t_role:
            actualDataNodes: read_write_db${0..1}.t_role_${0..1}
            # 配置分库策略
            databaseStrategy:
              complex:
                sharding-columns: id,name
                shardingAlgorithmName: role_database_complex
            # 配置分表策略
            tableStrategy:
              complex:
                sharding-columns: id,name
                shardingAlgorithmName: role_table_complex
            keyGenerateStrategy:
              column: id
              key-generator-name: snowflake
        # 配置分片算法
        sharding-algorithms:
          order_database_inline:
            type: INLINE
            props:
              algorithm-expression: read_write_db${id % 2}
          order_table_inline:
            type: INLINE
            props:
              algorithm-expression: t_order_${id % 2}
          user_database_complex:
            type: COMPLEX_INLINE
            props:
              algorithm-expression: read_write_db${((id % 2)+(role_id%2))%2}
          user_table_complex:
            type: CLASS_BASED
            props:
              strategy: COMPLEX
              algorithmClassName: com.zzh.springboot3.shardingsphere.UserShardingAlgorithm
          role_database_complex:
            type: COMPLEX_INLINE
            props:
              algorithm-expression: read_write_db${id % 2}
          role_table_complex:
            type: CLASS_BASED
            props:
              strategy: COMPLEX
              algorithmClassName: com.zzh.springboot3.shardingsphere.RoleShardingAlgorithm
          default_database_inline:
            type: INLINE
            props:
              algorithm-expression: read_write_db0
        #          default_table_inline:
        #            type: INLINE
        #            props:
        #              algorithm-expression: t_order_${id % 2}
        default-database-strategy:
          standard:
            sharding-column: id
            sharding-algorithm-name: default_database_inline
        #        default-table-strategy:
        #          standard:
        #            sharding-column: id
        #            sharding-algorithm-name: default_table_inline
        key-generators:
          snowflake:
            type: SNOWFLAKE
            props:
              worker-id: 0  # 可配置为你希望的 worker-id
        default-sharding-column: id
      readwrite-splitting:
        data-sources:
          read_write_db0:
            static-strategy:
              read-data-source-names: read1_db0,read2_db0
              write-data-source-name: write_db0
            load-balancer-name: round_robin
          read_write_db1:
            static-strategy:
              read-data-source-names: read1_db1,read2_db1
              write-data-source-name: write_db1
            load-balancer-name: round_robin
        load-balancers:
          round_robin:
            type: ROUND_ROBIN

logging:
  level:
    root: INFO
    org.springframework.transaction.interceptor.TransactionInterceptor: DEBUG
    org.springframework.transaction.support.TransactionSynchronizationManager: DEBUG
    org.springframework.orm.mybatis: DEBUG  # 额外增加 MyBatis 相关日志
    org.springframework.jdbc.support.JdbcTransactionManager: DEBUG
    io.github.resilience4j.circuitbreaker: DEBUG

resilience4j:
  circuitbreaker:
    instances:
      circuitBreakerA:
        slidingWindowType: COUNT_BASED    # 滑动窗口类型，支持时间或计数
        slidingWindowSize: 5       # 滑动窗口大小
        minimumNumberOfCalls: 3     # 最小调用次数，超过该值才开始判断是否要熔断
        failureRateThreshold: 50    # 失败率阈值，超过该值则开启熔断器（以百分比计算）
        waitDurationInOpenState: 60s # 熔断器打开后的等待时间，时间到后熔断器进入半开状态
        permittedNumberOfCallsInHalfOpenState: 3  # 半开状态下允许的调用次数
        automaticTransitionFromOpenToHalfOpenEnabled: true  # 自动从打开状态转换到半开状态
        maxWaitDurationInHalfOpenState: 2m   # 半开状态最多保持的时间
        #        recordExceptions:
        #          - java.io.IOException       # 记录为失败的异常类型
        #          - java.util.concurrent.TimeoutException
        ignoreExceptions:
          - com.zzh.springboot3.exception.BusinessException  # 被忽略的异常类型（这些异常不会触发熔断器）
  bulkhead:
    instances:
      bulkheadAnnotation:
        max-concurrent-calls: 1
        max-wait-duration: 0s
  thread-pool-bulkhead:
    instances:
      threadPoolBulkheadAnnotation:
        core-thread-pool-size: 1
        max-thread-pool-size: 1
        queue-capacity: 0
  rate-limiter:
    instances:
      rateLimiterA:
        #线程等待次数
        timeout-duration: 1s
        #一个周期内，允许的最大次数
        limit-for-period: 1
        #一个周期
        limit-refresh-period: 1s

  retry:
    instances:
      retryB:
        #最大重试次数
        max-attempts: 3
        #两次重试之间的时间间隔
        wait-duration: 500ms
        retry-exceptions:
          - java.lang.Throwable

zzh:
  resilience4j:
    circuit-breaker:
      circuitBreakerB:
        slidingWindowType: COUNT_BASED    # 滑动窗口类型，支持时间或计数
        slidingWindowSize: 5       # 滑动窗口大小
        minimumNumberOfCalls: 3     # 最小调用次数，超过该值才开始判断是否要熔断
        failureRateThreshold: 50    # 失败率阈值，超过该值则开启熔断器（以百分比计算）
        waitDurationInOpenState: 60s # 熔断器打开后的等待时间，时间到后熔断器进入半开状态
        permittedNumberOfCallsInHalfOpenState: 3  # 半开状态下允许的调用次数
        automaticTransitionFromOpenToHalfOpenEnabled: true  # 自动从打开状态转换到半开状态
        maxWaitDurationInHalfOpenState: 2m   # 半开状态最多保持的时间
  double-cache:
    cache-manager:
      default:
        capacity: 1024
      zzh:
        capacity: 1024
